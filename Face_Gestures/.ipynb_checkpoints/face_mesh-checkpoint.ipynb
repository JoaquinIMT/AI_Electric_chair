{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d52939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    " \n",
    "center_ids = [468, 473]\n",
    "\n",
    "while True:\n",
    "    # Image\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "    if ret is not True:\n",
    "        break\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb_image)\n",
    "    \n",
    "    if result.multi_face_landmarks != None:\n",
    "\n",
    "        for facial_landmarks in result.multi_face_landmarks:\n",
    "            for i in range(len(facial_landmarks.landmark)):\n",
    "                pt1 = facial_landmarks.landmark[i]\n",
    "                x = int(pt1.x * width)\n",
    "                y = int(pt1.y * height)\n",
    "                cv2.circle(image, (x, y), 1, (100, 100, 0), -1)\n",
    "    \n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "left_eye = [263, 249, 390, 373, 374, 380, 381, 382, 466, 388, 387, 386, 385, 384, 398]\n",
    "\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw the face mesh annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_face_landmarks:\n",
    "      for face_landmarks in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa721fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "class Facemesh:\n",
    "    def __init__(self):\n",
    "        left_eye = [263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398]\n",
    "        left_eyebrow = [276, 283, 282, 295, 285, 300, 293, 334, 296, 336]\n",
    "        lips = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 185, 40, 39, 37, 0, 267, 269, 270, 409, 78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308, 191, 80, 81, 82, 13, 312, 311, 310, 415]\n",
    "        right_eye = [33, 7, 163, 144, 145, 153, 154, 155, 133, 246, 161, 160, 159, 158, 157, 173]\n",
    "        right_eyebrow = [46, 53, 52, 65, 55, 70, 63, 105, 66, 107]\n",
    "        self.kps = left_eye + left_eyebrow + lips + right_eye + right_eyebrow\n",
    "        mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(  max_num_faces=1,\n",
    "                                            refine_landmarks=True,\n",
    "                                            min_detection_confidence=0.5,\n",
    "                                            min_tracking_confidence=0.5)\n",
    "\n",
    "    def get_image_landmarks(self,image):\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        return results\n",
    "            \n",
    "    def insert_dataframe(self, points):\n",
    "        points = np.array(points)\n",
    "        points = points.reshape(points.shape[1],points.shape[0])\n",
    "        df = pd.DataFrame(np.array(points))\n",
    "        print(df.to_string())\n",
    "        \n",
    "                        \n",
    "    def draw_image_kps(self,image,facial_landmarks):\n",
    "        height, width, _ = image.shape\n",
    "        points = []\n",
    "        for i in range(len(facial_landmarks.landmark)):\n",
    "            if i in self.kps :\n",
    "                pt= facial_landmarks.landmark[i]\n",
    "                points.append( [pt.x, pt.y] )\n",
    "                x = int(pt.x * width)\n",
    "                y = int(pt.y * height)\n",
    "                cv2.circle(image, (x, y), 1, (0, 100, 255), -1)\n",
    "        self.insert_dataframe(points)\n",
    "        cv2.imshow(\"Image\", cv2.flip(image, 1))\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8c6ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-689fbf23392c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_face_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mface_landmarks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmulti_face_lm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_face_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mface_mesh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image_kps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mface_landmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-dab8ab8acedb>\u001b[0m in \u001b[0;36mdraw_image_kps\u001b[1;34m(self, image, facial_landmarks)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkps\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mpt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfacial_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_mesh = Facemesh()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "    \n",
    "    multi_face_lm = face_mesh.get_image_landmarks(image)\n",
    "    if multi_face_lm.multi_face_landmarks:\n",
    "        for face_landmarks in multi_face_lm.multi_face_landmarks:\n",
    "            face_mesh.draw_image_kps(image,face_landmarks)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934671b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388, 387, 386, 385, 384, 398]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "left_eye = [(263, 249), (249, 390), (390, 373), (373, 374),\n",
    "                               (374, 380), (380, 381), (381, 382), (382, 362),\n",
    "                               (263, 466), (466, 388), (388, 387), (387, 386),\n",
    "                               (386, 385), (385, 384), (384, 398), (398, 362)]\n",
    "\n",
    "FACEMESH_LIPS = [(61, 146), (146, 91), (91, 181), (181, 84), (84, 17),\n",
    "                           (17, 314), (314, 405), (405, 321), (321, 375),\n",
    "                           (375, 291), (61, 185), (185, 40), (40, 39), (39, 37),\n",
    "                           (37, 0), (0, 267),\n",
    "                           (267, 269), (269, 270), (270, 409), (409, 291),\n",
    "                           (78, 95), (95, 88), (88, 178), (178, 87), (87, 14),\n",
    "                           (14, 317), (317, 402), (402, 318), (318, 324),\n",
    "                           (324, 308), (78, 191), (191, 80), (80, 81), (81, 82),\n",
    "                           (82, 13), (13, 312), (312, 311), (311, 310),\n",
    "                           (310, 415), (415, 308)]\n",
    "LEFT_EYEBROW = [(276, 283), (283, 282), (282, 295),\n",
    "                                   (295, 285), (300, 293), (293, 334),\n",
    "                                   (334, 296), (296, 336)]\n",
    "RIGHT_EYE = [(33, 7), (7, 163), (163, 144), (144, 145),\n",
    "                                (145, 153), (153, 154), (154, 155), (155, 133),\n",
    "                                (33, 246), (246, 161), (161, 160), (160, 159),\n",
    "                                (159, 158), (158, 157), (157, 173), (173, 133)]\n",
    "RIGHT_EYEBROW = [(46, 53), (53, 52), (52, 65), (65, 55),\n",
    "                                    (70, 63), (63, 105), (105, 66), (66, 107)]\n",
    "a = []\n",
    "for i in left_eye:\n",
    "    if i[0] not in a:\n",
    "        a.append(i[0])\n",
    "    if  i[1] not in a:\n",
    "        a.append(i[1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e1bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
